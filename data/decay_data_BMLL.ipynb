{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6718bb-9cdf-4404-8846-6725de316799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bmll2 as b2\n",
    "from bmll2 import reference, Security, NormalisedSecurity, SparkHelper, get_market_data, get_market_data_range, VenueMarketError, get_market_tables, save_spark_dataframe, load_spark_dataframe\n",
    "b2.get_file('modules/auxiliary_functions.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c22b7e-0705-448a-9a34-59c39a4ffe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import auxiliary_functions as af\n",
    "\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import StringDtype\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import LogFormatterSciNotation\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdae52d-fc13-4c12-b54e-c02ebcdc7831",
   "metadata": {},
   "source": [
    "## Data processing for plotting the convex post execution decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d1744-21f6-422c-ab21-25d8a6024eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'GRT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b4698-b08d-48ba-9f0f-3c3b8f771a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2.get_file('top_100(Volume)/GRT.csv')\n",
    "stock_data = pd.read_csv('GRT.csv', parse_dates = ['DateTime', 'Date'])\n",
    "stock_data = stock_data.rename(columns = {'Ticker' : 'RIC'})\n",
    "stock_data = stock_data.sort_values(['DateTime', 'ExchangeSequenceNo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69029b29-b4d0-43ee-9a7b-7f6ea9789fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2.get_file('test_data/homo_4_immediate(100).csv')\n",
    "impact_data = pd.read_csv('homo_4_immediate(100).csv', parse_dates = ['Date', 'Start time', 'End time'])\n",
    "\n",
    "stock_AD_data = impact_data[impact_data['RIC'] == ticker][['RIC', 'Date', '20 AD volatility', '20 AD volume']]\n",
    "stock_AD_data = stock_AD_data.drop_duplicates(subset = ['Date']).reset_index(drop = True)\n",
    "\n",
    "del impact_data\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca8fd3-bfca-426b-9ac1-debba268e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impact_df_decay(metaorders_list, timing_method = 'immediate'): \n",
    "    \n",
    "    num_trades = len(metaorders_list)\n",
    "    \n",
    "    features = pd.DataFrame(columns = ['RIC', 'Date', 'Start time', 'End time', 'daily volume', 'intraday volatility',\n",
    "                                       'number child orders', 'volume traded', 'trade sign', 'impact(simple)', 'Mid-price before', 'Mid-price after(immediate)'])\n",
    "    for i in range(num_trades):\n",
    "        metaorder = metaorders_list[i]\n",
    "\n",
    "        if metaorder.empty:\n",
    "            continue\n",
    "\n",
    "        intention  = metaorder.iloc[0]['Trade Sign']\n",
    "        ave_impact = af.impact(metaorder, timing_method = timing_method, impact_method = 'simple')\n",
    "        n          = metaorder.shape[0]\n",
    "        volume     = sum(metaorder.loc[:, 'Volume'])\n",
    "\n",
    "        features.at[i, 'RIC']                       = metaorder['RIC'].iloc[0]\n",
    "        features.at[i, 'Date']                      = metaorder['Date'].iloc[0]\n",
    "        features.at[i, 'Start time']                = metaorder['DateTime'].iloc[0]\n",
    "        features.at[i, 'End time']                  = metaorder['DateTime'].iloc[-1]\n",
    "        features.at[i, 'daily volume']              = metaorder['Daily Volume'].iloc[0]\n",
    "        features.at[i, 'intraday volatility']       = metaorder['Daily Volatility'].iloc[0]\n",
    "        features.at[i, 'number child orders']       = n\n",
    "        features.at[i, 'volume traded']             = volume\n",
    "        features.at[i, 'trade sign']                = intention\n",
    "        features.at[i, 'impact(simple)']            = ave_impact\n",
    "        features.at[i, 'Mid-price before']          = metaorder['Mid-price before'].iloc[0]\n",
    "        features.at[i, 'Mid-price after(immediate)'] = metaorder['Mid-price after(immediate)'].iloc[-1]\n",
    "        \n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae62c8-361a-4ee0-9cf2-cd3151ea4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stock_mid_prices = get_market_data_range('XJSE', start_date = '2023-01-03', end_date = '2025-12-31',\n",
    "                                       table_name = 'l1', ticker = 'stock', df_engine = 'polars',\n",
    "                                      columns = ['Ticker', 'TradeDate', 'LocalTimestamp', 'BidPrice1', 'BidQuantity1', 'AskPrice1', 'AskQuantity1',\n",
    "                                                 'ExchangeSequenceNo', 'MarketState'])\n",
    "stock_mid_prices = stock_mid_prices.to_pandas()#toPandas()\n",
    "stock_mid_prices = stock_mid_prices[stock_mid_prices['MarketState'] == 'CONTINUOUS_TRADING']\n",
    "stock_mid_prices = stock_mid_prices.sort_values(['LocalTimestamp', 'ExchangeSequenceNo'])\n",
    "stock_mid_prices['Mid-price'] = (stock_mid_prices['BidPrice1'] + stock_mid_prices['AskPrice1']) / 2\n",
    "stock_mid_prices.head()\n",
    "\n",
    "# I can do 3 entire years worth of l1 data at a time for GRT. Takes 60 to load\n",
    "# I can do 3 entire years worth of l1 data at a time for GFI. Takes 2.5 minutes to load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719bcc37-c619-4846-9d5a-94d577a42c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "N                   = 20\n",
    "trader_distribution = 'power'\n",
    "alpha               = 2\n",
    "identifier          = f'{trader_distribution}_{N}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb48d79-28e8-4065-a425-1632e05fb828",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "impact_data = []\n",
    "for date, day_D in stock.groupby('Date', sort = True):\n",
    "        print(date)\n",
    "\n",
    "        trades = day_D.loc[day_D['Price'] != 0]\n",
    "    \n",
    "        N = N\n",
    "        f = af.trader_participation(N = N, method = trader_distribution, alpha = alpha, f_min = 1, f_max = trades.shape[0], seed = 1)\n",
    "        c = af.cumulative_probs(f)\n",
    "\n",
    "        if trades.empty:\n",
    "            continue\n",
    "\n",
    "        output = af.orders(N = N, trades = trades, cumulative_probs = c)\n",
    "        for n in range(N):\n",
    "            \n",
    "            trader_n_trades = trades.iloc[output[n], ]\n",
    "           \n",
    "            if trader_n_trades.empty:\n",
    "                continue\n",
    "\n",
    "            trader_n_metaorders = af.metaorders(trader_n_trades)\n",
    "            \n",
    "            if len(trader_n_metaorders) < 10:\n",
    "                continue\n",
    "\n",
    "            trader_n_features = impact_df_decay(trader_n_metaorders, timing_method = 'immediate')\n",
    "            trader_n_features['20 AD volatility'] = GRT_AD[GRT_AD['Date'] == date]['20 AD volatility'].iloc[0] \n",
    "            trader_n_features['20 AD volume'] = GRT_AD[GRT_AD['Date'] == date]['20 AD volume'].iloc[0]\n",
    "            \n",
    "            if not trader_n_features.empty and not trader_n_features.isna().all().all():\n",
    "                impact_data.append(trader_n_features)\n",
    "\n",
    "\n",
    "\n",
    "impact_data   = pd.concat(impact_data, ignore_index = True)\n",
    "exclude_cols = ['RIC', 'Date', 'Start time', 'End time']\n",
    "numeric_cols = [col for col in impact_data.columns if col not in exclude_cols]\n",
    "impact_data[numeric_cols] = impact_data[numeric_cols].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "impact_data['Date']          = pd.to_datetime(impact_data['Date']).dt.normalize()\n",
    "impact_data['Start time']    = pd.to_datetime(impact_data['Start time'], format = 'mixed')\n",
    "impact_data['End time']      = pd.to_datetime(impact_data['End time'], format = 'mixed')\n",
    "impact_data['duration(min)'] = (impact_data['End time'] - impact_data['Start time']).dt.total_seconds() / 60\n",
    "durations_GRT               = impact_data['duration(min)']\n",
    "\n",
    "impact_data.to_csv(f'{ticker}_{identifier}_decay.csv', index = False)\n",
    "b2.put_file(f'{ticker}_{identifier}_decay.csv', 'test_data')\n",
    "\n",
    "# takes about 6 minutes to run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-stable",
   "language": "python",
   "name": "py311-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
