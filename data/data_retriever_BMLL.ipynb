{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dad75cc-a1cb-4adb-af2f-6efdfa92e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import bmll2 as b2\n",
    "from bmll2 import reference, Security, NormalisedSecurity, SparkHelper, get_market_data, get_market_data_range, VenueMarketError, save_spark_dataframe, load_spark_dataframe\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3f006a4-cd21-42c7-8562-b935b55c3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jse_securities = reference.query(MIC = 'XJSE')\n",
    "#jse_securities = jse_securities[(jse_securities['InstrumentType'] == 'Equity') & (jse_securities['IsAlive'] == True)]\n",
    "#jse_listing_ids = dict(zip(jse_securities['Ticker'], jse_securities['ListingId']))\n",
    "#jse_tickers    = jse_securities['Ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5de40c69-5ce4-4dc5-8f1d-4ea887650127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769359338"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jse_listing_ids['AGL']\n",
    "#jse_securities[jse_securities['Ticker'] == 'AGL'][['Ticker', 'ListingId']]\n",
    "#jse_securities.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4fa3b-18b0-42fa-a0f1-9df3dff23bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trades = market_data.all_trades()\n",
    "#trades = trades[trades['market_state'] == 'CONTINUOUS_TRADING']\n",
    "#trades.aggressor_side.value_counts()\n",
    "#trades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db73adf-1a84-4e8e-aa14-557098f823b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#incremental_book = market_data.incremental_book_L3()\n",
    "#incremental_book = incremental_book[incremental_book['market_state'] == 'CONTINUOUS_TRADING']\n",
    "#incremental_book[incremental_book['order_executed'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad552af-dd26-4802-80d3-8c2a66989b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sec = NormalisedSecurity.from_listing_id(769359338, '2025-12-12')\n",
    "#md = sec.market_data()\n",
    "#bbo = md.best_bid_offer()\n",
    "#bbo = bbo[bbo.market_state == 'CONTINUOUS_TRADING'].sort_values('event_timestamp')\n",
    "#bbo.head()\n",
    "#mid_price = (bbo.best_bid_price + bbo.best_ask_price) / 2\n",
    "#vol = np.log(mid_price.max()) - np.log(mid_price.min())\n",
    "#vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bbfa8d-0468-4a6f-9507-6651cf7091cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#test = get_market_data_range('XJSE', start_date = '2023-01-01', end_date = '2023-02-28', ticker = 'AGL',\n",
    "#                             table_name = 'l1', df_engine = 'polars', columns = ['TradeDate', 'BidPrice1', 'AskPrice1', 'MarketState'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9da5e1-f50f-4a36-9635-a9eb55e9dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test.to_pandas()\n",
    "#test = test[test['MarketState'] == 'CONTINUOUS_TRADING']\n",
    "#test.MarketState.unique()\n",
    "#midprice = (test['AskPrice1'] + test['BidPrice1']) / 2\n",
    "#test.insert(loc = 1, column = 'Mid-price', value = midprice)\n",
    "\n",
    "#daily_vol = (test.groupby('TradeDate')['Mid-price'].apply(lambda x: np.log(x.max()) - np.log(x.min()))).rename('Daily Volatility')\n",
    "#trade_plus.insert(loc = 5, column = 'Daily Volatility', value = daily_vol)\n",
    "#trade_plus.insert(loc = 6, column = 'Daily Volume', value = trade_plus['Volume'].sum())\n",
    "#trade_plus.head()\n",
    "#test.head()\n",
    "#daily_vol\n",
    "#test['Daily Volatility'] = test['TradeDate'].map(daily_vol)\n",
    "#test.head()\n",
    "#test = pd.merge(test, daily_vol, on = \"TradeDate\", how = \"left\")\n",
    "#test.sort_values('EventTimestamp').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0efb919d-4e5e-4d94-bddd-61b4327bb93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "957642"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%time\n",
    "trade_plus = get_market_data_range('XJSE', start_date = '2023-01-01', end_date = '2023-06-30',\n",
    "                                   table_name = 'trades-plus', df_engine = 'polars', ticker = 'ABG',\n",
    "                                   columns = ['Classification', 'MIC', 'Ticker', 'ListingId', 'TradeDate',\n",
    "                                              'LocalTradeTimestamp', 'ExchangeSequenceNo', 'AggressorSide',\n",
    "                                              'Price', 'Size', 'PreTradeMid1ms', 'PostTradeMid1ms'])\n",
    "trade_plus = trade_plus.to_pandas()\n",
    "trades_plus = trade_plus.groupby('TradeDate')\n",
    "trade_plus = trade_plus[(trade_plus['Classification'] == 'LIT_CONTINUOUS')]\n",
    "trade_plus = trade_plus[['MIC', 'Ticker', 'ListingId', 'TradeDate', 'LocalTradeTimestamp', 'ExchangeSequenceNo',\n",
    "                         'AggressorSide', 'Price', 'Size', 'PreTradeMid1ms', 'PostTradeMid1ms']]\n",
    "trade_plus['AggressorSide'] = trade_plus['AggressorSide'].map({1 : 1, 2 : -1, 0 : 0})\n",
    "trade_plus = trade_plus.rename(columns = {'AggressorSide' : 'Trade Sign', 'PreTradeMid1ms' : 'Mid-price before',\n",
    "                                          'PostTradeMid1ms' : 'Mid-price after(immediate)', 'Size' : 'Volume',\n",
    "                                          'LocalTradeTimestamp' : 'DateTime', 'TradeDate' : 'Date'})\n",
    "midprice_after_delayed = trade_plus['Mid-price before'].shift(-1)\n",
    "trade_plus.insert(loc = 10, column = 'Mid-price after(delayed)', value = midprice_after_delayed)\n",
    "trade_plus.sort_values('DateTime').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca1ebf-396f-441d-b7af-bdabb52b94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1 = get_market_data_range('XJSE', start_date = '2023-01-10', end_date = '2023-01-10', ticker = 'RMH',\n",
    "#                            table_name = 'l1', df_engine = 'polars')\n",
    "#l1 = l1.to_pandas()\n",
    "#l1 = l1[l1['MarketState'] == 'CONTINUOUS_TRADING']\n",
    "#midprice = (l1['AskPrice1'] + l1['BidPrice1']) / 2\n",
    "#l1.insert(loc = 5, column = 'Mid-price', value = midprice)\n",
    "#l1 = l1.rename(columns = {'TradeDate' : 'Date'})\n",
    "#daily_vol = (l1.groupby('Date')['Mid-price'].apply(lambda x: np.log(x.max()) - np.log(x.min()))).rename('Daily Volatility')\n",
    "#daily_vol\n",
    "#trade_plus = pd.merge(trade_plus, daily_vol, on = 'Date', how = 'left')\n",
    "#trade_plus.insert(loc = 6, column = 'Daily Volume', value = trade_plus['Volume'].sum())\n",
    "#trade_plus.sort_values(['DateTime', 'ExchangeSequenceNo'])\n",
    "#trade_plus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc636578-b6c9-4771-aaad-804ee75a5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#midprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258b64d-16e6-4cf0-a51b-29046fa77388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trade_plus[(trade_plus['DateTime'] >= '2023-01-03 16:45:58.046172') & \n",
    "#            (trade_plus['DateTime'] <= '2023-01-04 09:01:58.046172')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a09e2-fec3-4e58-891c-d6d93f2087b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1 = get_market_data_range('XJSE', start_date = '2023-01-05', end_date = '2023-01-05', ticker = 'AGL',\n",
    "#                            table_name = 'l1', df_engine = 'polars')\n",
    "#l1 = l1.to_pandas()\n",
    "#l1 = l1[l1['MarketState'] == 'CONTINUOUS_TRADING']\n",
    "#midprice = (l1['AskPrice1'] + l1['BidPrice1']) / 2\n",
    "#l1.insert(loc = 5, column = 'Mid-price', value = midprice)\n",
    "#l1 = l1.rename(columns = {'TradeDate' : 'Date'})\n",
    "#daily_vol = (l1.groupby('Date')['Mid-price'].apply(lambda x: np.log(x.max()) - np.log(x.min()))).rename('Daily Volatility')\n",
    "#trade_plus = pd.merge(trade_plus, daily_vol, on = 'Date', how = 'left')\n",
    "#trade_plus.insert(loc = 5, column = 'Daily Volatility', value = daily_vol)\n",
    "#trade_plus.insert(loc = 6, column = 'Daily Volume', value = trade_plus['Volume'].sum())\n",
    "#trade_plus.sort_values(['DateTime', 'ExchangeSequenceNo'])\n",
    "#daily_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb9bb09-5e07-43d3-be51-b7dce5bfd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ticker, starting_date, ending_date):\n",
    "\n",
    "    #if isinstance(startingdate, str):\n",
    "    #    date = pd.to_datetime(date).date()\n",
    "    \n",
    "    try:\n",
    "        trade_plus = get_market_data_range('XJSE',start_date = starting_date, end_date = ending_date,\n",
    "                                   table_name = 'trades-plus', df_engine = 'polars', ticker = ticker,\n",
    "                                   columns = ['Classification', 'MIC', 'Ticker', 'ListingId', 'TradeDate',\n",
    "                                              'LocalTradeTimestamp', 'ExchangeSequenceNo', 'AggressorSide',\n",
    "                                              'Price', 'Size', 'PreTradeMid1ms', 'PostTradeMid1ms'])\n",
    "    except VenueMarketError:\n",
    "        return None\n",
    "        \n",
    "    trade_plus = trade_plus.to_pandas()\n",
    "    trade_plus = trade_plus[(trade_plus['Classification'] == 'LIT_CONTINUOUS')]\n",
    "    \n",
    "    if trade_plus is None or trade_plus.empty:\n",
    "        return None\n",
    "        \n",
    "    trade_plus = trade_plus[['MIC', 'Ticker', 'ListingId', 'TradeDate', 'LocalTradeTimestamp', 'ExchangeSequenceNo',\n",
    "                             'AggressorSide', 'Price', 'Size', 'PreTradeMid1ms', 'PostTradeMid1ms']]\n",
    "    trade_plus['AggressorSide'] = trade_plus['AggressorSide'].map({1 : 1, 2 : -1, 0 : 0})\n",
    "    trade_plus = trade_plus.rename(columns = {'AggressorSide' : 'Trade Sign', 'PreTradeMid1ms' : 'Mid-price before',\n",
    "                                              'PostTradeMid1ms' : 'Mid-price after(immediate)', 'Size' : 'Volume',\n",
    "                                              'LocalTradeTimestamp' : 'DateTime', 'TradeDate' : 'Date'})\n",
    "    midprice_after_delayed = trade_plus['Mid-price before'].shift(-1)\n",
    "    trade_plus.insert(loc = 11, column = 'Mid-price after(delayed)', value = midprice_after_delayed)\n",
    "    \n",
    "    l1 = get_market_data_range('XJSE', start_date = starting_date, end_date = ending_date, ticker = ticker,\n",
    "                               table_name = 'l1', df_engine = 'polars')\n",
    "    l1 = l1.to_pandas()\n",
    "    l1 = l1[l1['MarketState'] == 'CONTINUOUS_TRADING']\n",
    "    midprice = (l1['AskPrice1'] + l1['BidPrice1']) / 2\n",
    "    l1.insert(loc = 5, column = 'Mid-price', value = midprice)\n",
    "    l1 = l1.rename(columns = {'TradeDate' : 'Date'})\n",
    "    daily_vol = (l1.groupby('Date', as_index = False)['Mid-price'].apply(lambda x: np.log(x.max()) - np.log(x.min()))).rename(columns = {'Mid-price' : 'Daily Volatility'})\n",
    "    trade_plus = pd.merge(trade_plus, daily_vol, on = 'Date', how = 'left')\n",
    "\n",
    "    col = 'Daily Volatility'\n",
    "    cols = list(trade_plus.columns)\n",
    "    cols.insert(6, cols.pop(cols.index(col)))\n",
    "    trade_plus = trade_plus[cols]\n",
    "    daily_volume = (trade_plus.groupby('Date', as_index = False)['Volume'].sum().rename(columns = {'Volume' : 'Daily Volume'}))\n",
    "    trade_plus = pd.merge(trade_plus, daily_volume, on = 'Date', how = 'left')\n",
    "    col = 'Daily Volume'\n",
    "    cols = list(trade_plus.columns)\n",
    "    cols.insert(6, cols.pop(cols.index(col)))\n",
    "    trade_plus = trade_plus[cols]\n",
    "    #trade_plus.insert(loc = 6, column = 'Daily Volume', value = trade_plus['Volume'].sum())\n",
    "    \n",
    "    trade_plus.sort_values(['DateTime', 'ExchangeSequenceNo'])\n",
    "    return trade_plus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f8fa1b5-a5ca-4be3-b3ce-ccf05cd5768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top40_tickers = [\n",
    "    \"ABG\",  # ABSA\n",
    "    \"AGL\",  # Anglo American\n",
    "    \"ANG\",  # Anglogold Ashanti\n",
    "    \"ANH\",  # AB InBev\n",
    "    \"APN\",  # Aspen Pharmacare\n",
    "    \"BHG\",  # BHP Group\n",
    "    \"BID\",  # Bidcorp\n",
    "    \"BVT\",  # Bidvest\n",
    "    \"BTI\",  # British American Tobacco\n",
    "    \"CPI\",  # Capitec\n",
    "    \"CLS\",  # Clicks\n",
    "    \"DSY\",  # Discovery  \n",
    "    \"EXX\",  # Exxaro\n",
    "    \"FSR\",  # FirstRand\n",
    "    \"GLN\",  # Glencore\n",
    "    \"GFI\",  # Gold Fields\n",
    "    \"GRT\",  # Growthpoint\n",
    "    \"IMP\",  # Impala Platinum\n",
    "    \"INL\",  # Investec Ltd\n",
    "    \"INP\",  # Investec PLC\n",
    "    \"MNP\",  # Mondi\n",
    "    \"MRP\",  # Mr Price\n",
    "    \"MTN\",  # MTN Group\n",
    "    \"NPN\",  # Naspers\n",
    "    \"NED\",  # Nedbank\n",
    "    \"NRP\",  # NEPI Rockcastle\n",
    "    \"OMU\",  # Old Mutual\n",
    "    \"PRX\",  # Prosus\n",
    "    \"RNI\",  # Reinet Investments\n",
    "    \"REM\",  # Remgro\n",
    "    \"RMH\",  # RMB\n",
    "    \"SLM\",  # Sanlam\n",
    "    \"SOL\",  # Sasol\n",
    "    \"SHP\",  # Shoprite\n",
    "    \"SBK\",  # Standard Bank\n",
    "    \"VAL\",  # Valterra platinum\n",
    "    \"VOD\",  # Vodacom\n",
    "    \"WHL\"   # Woolworths\n",
    "]\n",
    "\n",
    "start_dates = pd.date_range(start = '2023-01-01', end = '2025-12-31', freq = 'MS', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2023-01-01', end = '2025-12-31', freq = 'M', inclusive = 'both').date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9670336-c425-42f3-968c-8a674db043d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABG\n",
      "AGL\n",
      "ANG\n",
      "ANH\n",
      "APN\n",
      "BHG\n",
      "BID\n",
      "BVT\n",
      "BTI\n",
      "CPI\n",
      "CLS\n",
      "DSY\n",
      "EXX\n",
      "FSR\n",
      "GLN\n",
      "GFI\n",
      "GRT\n",
      "IMP\n",
      "INL\n",
      "INP\n",
      "MNP\n",
      "MRP\n",
      "MTN\n",
      "NPN\n",
      "NED\n",
      "NRP\n",
      "OMU\n",
      "PRX\n",
      "RNI\n",
      "REM\n",
      "RMH\n",
      "SLM\n",
      "SOL\n",
      "SHP\n",
      "SBK\n",
      "VAL\n",
      "VOD\n",
      "WHL\n"
     ]
    }
   ],
   "source": [
    "for ticker in top40_tickers:\n",
    "    print(ticker)\n",
    "    stock = []\n",
    "    for i in range(len(start_dates)):\n",
    "        data = get_data(ticker, start_dates[i], end_dates[i])\n",
    "        if data is not None:\n",
    "            stock.append(data)\n",
    "    \n",
    "    stock_data = pd.concat(stock, ignore_index = True)\n",
    "    stock_data.to_csv(f'{ticker}.csv', index = False)\n",
    "    b2.put_file(f'{ticker}.csv', 'top_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1096e5b-22c9-43bf-a2e5-4cc8897d398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to do this because the ticker for VAL was AMS before 2025-05-28\n",
    "%%time\n",
    "start_dates = pd.date_range(start = '2023-01-01', end = '2025-04-30', freq = 'MS', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2023-01-01', end = '2025-04-30', freq = 'M', inclusive = 'both').date\n",
    "\n",
    "VAL = []\n",
    "for i in range(len(start_dates)):\n",
    "    print(start_dates[i], end_dates[i])\n",
    "    data = get_data('AMS', start_dates[i], end_dates[i])\n",
    "    if data is not None:\n",
    "        VAL.append(data)\n",
    "\n",
    "start_dates = pd.date_range(start = '2025-05-01', end = '2025-05-27', freq = 'B', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2025-05-01', end = '2025-05-27', freq = 'B', inclusive = 'both').date\n",
    "\n",
    "for i in range(len(start_dates)):\n",
    "    print(start_dates[i], end_dates[i])\n",
    "    data = get_data('AMS', start_dates[i], end_dates[i])\n",
    "    if data is not None:\n",
    "        VAL.append(data)\n",
    "\n",
    "start_dates = pd.date_range(start = '2025-05-27', end = '2025-05-31', freq = 'B', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2025-05-27', end = '2025-05-31', freq = 'B', inclusive = 'both').date\n",
    "\n",
    "for i in range(len(start_dates)):\n",
    "    print(start_dates[i], end_dates[i])\n",
    "    data = get_data('VAL', start_dates[i], end_dates[i])\n",
    "    if data is not None:\n",
    "        VAL.append(data)\n",
    "\n",
    "start_dates = pd.date_range(start = '2025-06-01', end = '2025-12-31', freq = 'MS', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2025-06-01', end = '2025-12-31', freq = 'M', inclusive = 'both').date\n",
    "\n",
    "for i in range(len(start_dates)):\n",
    "    print(start_dates[i], end_dates[i])\n",
    "    data = get_data('VAL', start_dates[i], end_dates[i])\n",
    "    if data is not None:\n",
    "        VAL.append(data)\n",
    "\n",
    "VAL_data = pd.concat(VAL, ignore_index = True)\n",
    "VAL_data['Ticker'] = 'VAL'\n",
    "VAL_data.to_csv('VAL.csv', index = False)\n",
    "b2.put_file('VAL.csv', 'top_40')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-stable",
   "language": "python",
   "name": "py311-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
