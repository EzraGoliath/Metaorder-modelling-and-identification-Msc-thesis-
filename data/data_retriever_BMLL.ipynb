{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9a33c0-489d-4e32-9798-2d3f772eaa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (2.0.3)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from pandas) (1.26.0)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb740e0-fef5-43cb-b8b8-c08d5b71da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import bmll2 as b2\n",
    "from bmll2 import reference, Security, NormalisedSecurity, SparkHelper, get_market_data, get_market_data_range, VenueMarketError, save_spark_dataframe, load_spark_dataframe\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2042490e-9b0b-4398-9d59-872eab256acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(exchange, ticker, starting_date, ending_date):\n",
    "\n",
    "    #if isinstance(startingdate, str):\n",
    "    #    date = pd.to_datetime(date).date()\n",
    "    \n",
    "    try:\n",
    "        trade_plus = get_market_data_range([exchange], start_date = starting_date, end_date = ending_date,\n",
    "                                   table_name = 'trades-plus', df_engine = 'polars', ticker = ticker,\n",
    "                                   columns = ['Classification', 'MIC', 'Ticker', 'ListingId', 'TradeDate',\n",
    "                                              'LocalTradeTimestamp', 'ExchangeSequenceNo', 'AggressorSide',\n",
    "                                              'Price', 'Size', 'PreTradeMid1ms', 'PostTradeMid1ms'])\n",
    "    except VenueMarketError:\n",
    "        return None\n",
    "        \n",
    "    trade_plus = trade_plus.to_pandas()\n",
    "    trade_plus = trade_plus[(trade_plus['Classification'] == 'LIT_CONTINUOUS')]\n",
    "    \n",
    "    if trade_plus is None or trade_plus.empty:\n",
    "        return None\n",
    "        \n",
    "    trade_plus = trade_plus[['MIC', 'Ticker', 'ListingId', 'TradeDate', 'LocalTradeTimestamp', 'ExchangeSequenceNo',\n",
    "                             'AggressorSide', 'Price', 'Size', 'PreTradeMid1ms', 'PostTradeMid1ms']]\n",
    "    trade_plus['AggressorSide'] = trade_plus['AggressorSide'].map({1 : 1, 2 : -1, 0 : 0})\n",
    "    trade_plus = trade_plus.rename(columns = {'AggressorSide' : 'Trade Sign', 'PreTradeMid1ms' : 'Mid-price before',\n",
    "                                              'PostTradeMid1ms' : 'Mid-price after(immediate)', 'Size' : 'Volume',\n",
    "                                              'LocalTradeTimestamp' : 'DateTime', 'TradeDate' : 'Date'})\n",
    "    midprice_after_delayed = trade_plus['Mid-price before'].shift(-1)\n",
    "    trade_plus.insert(loc = 11, column = 'Mid-price after(delayed)', value = midprice_after_delayed)\n",
    "    \n",
    "    l1 = get_market_data_range(exchange, start_date = starting_date, end_date = ending_date, ticker = ticker,\n",
    "                               table_name = 'l1', df_engine = 'polars')\n",
    "    l1 = l1.to_pandas()\n",
    "    l1 = l1[l1['MarketState'] == 'CONTINUOUS_TRADING']\n",
    "    midprice = (l1['AskPrice1'] + l1['BidPrice1']) / 2\n",
    "    l1.insert(loc = 5, column = 'Mid-price', value = midprice)\n",
    "    l1 = l1.rename(columns = {'TradeDate' : 'Date'})\n",
    "    l1 = l1.sort_values(by = ['Date', 'ExchangeSequenceNo'])\n",
    "    daily_vol = (l1.groupby('Date', as_index = False)['Mid-price'].apply(lambda x: (x.max() - x.min()) / x.iloc[0])).rename(columns = {'Mid-price' : 'Daily Volatility'})\n",
    "    daily_vol_alt = (l1.groupby('Date', as_index = False)['Mid-price'].apply(lambda x: np.log(x.max()) - np.log(x.min()))).rename(columns = {'Mid-price' : 'Daily Volatility(alt)'})\n",
    "    trade_plus = pd.merge(trade_plus, daily_vol, on = 'Date', how = 'left')\n",
    "    trade_plus = pd.merge(trade_plus, daily_vol_alt, on = 'Date', how = 'left')\n",
    "\n",
    "    col = 'Daily Volatility'\n",
    "    cols = list(trade_plus.columns)\n",
    "    cols.insert(6, cols.pop(cols.index(col)))\n",
    "    \n",
    "    #col = 'Daily Volatility(alt)'\n",
    "    #cols = list(trade_plus.columns)\n",
    "    #cols.insert(7, cols.pop(cols.index(col)))\n",
    "    \n",
    "    trade_plus = trade_plus[cols]\n",
    "    daily_volume = (trade_plus.groupby('Date', as_index = False)['Volume'].sum().rename(columns = {'Volume' : 'Daily Volume'}))\n",
    "    trade_plus = pd.merge(trade_plus, daily_volume, on = 'Date', how = 'left')\n",
    "    col = 'Daily Volume'\n",
    "    cols = list(trade_plus.columns)\n",
    "    cols.insert(6, cols.pop(cols.index(col)))\n",
    "    trade_plus = trade_plus[cols]\n",
    "    #trade_plus.insert(loc = 6, column = 'Daily Volume', value = trade_plus['Volume'].sum())\n",
    "    \n",
    "    trade_plus.sort_values(['DateTime', 'ExchangeSequenceNo'])\n",
    "    return trade_plus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b2dc57-4e67-43e0-8984-0e147e0e04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2.get_file('other/JSE_listed_securities.xlsx')\n",
    "JSE_listed_securities = pd.read_excel('JSE_listed_securities.xlsx')\n",
    "\n",
    "JSE_listed_securities = JSE_listed_securities.drop(columns = ['Value', 'Change', 'Unnamed: 4', 'High', 'Low'])\n",
    "JSE_listed_securities = JSE_listed_securities.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa57d52-5354-4eee-99b4-b71dc4ae4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    if(isinstance(x, (int, float))):\n",
    "        ans = x\n",
    "    elif(x[-1:] == 'M'):\n",
    "        ans = float(x[:-1]) * 1000000\n",
    "    elif(x[-1:] == 'K'):\n",
    "        ans = float(x[:-1]) * 1000\n",
    "    else:\n",
    "        ans = 0\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679c9f36-dbeb-4448-8357-1f23318e94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSE_listed_securities['Volume'] = JSE_listed_securities['Volume'].apply(clean)\n",
    "JSE_listed_securities = JSE_listed_securities.sort_values('Volume', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acb1ebac-a75e-4cda-a585-041508d402c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_data(exchange, ticker, start, end):\n",
    "    data = get_data(exchange, ticker, start, end)\n",
    "    return data is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48608a6-d134-408e-b5b9-9253a35731c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top100_tickers = []\n",
    "i = 0\n",
    "\n",
    "while len(top100_tickers) < 100 and i < len(JSE_listed_securities):\n",
    "    ticker = JSE_listed_securities['Symbol'].iloc[i]\n",
    "\n",
    "    ok_2023 = has_data('XJSE', ticker, '2023-01-01', '2023-01-07')\n",
    "    ok_2025 = has_data('XJSE', ticker, '2025-12-01', '2025-12-07')\n",
    "\n",
    "    if ok_2023 and ok_2025:\n",
    "        top100_tickers.append(ticker)\n",
    "    else:\n",
    "        print(f'Skipping {ticker}: 2023 = {ok_2023}, 2025 = {ok_2025}')\n",
    "\n",
    "    i += 1\n",
    "\n",
    "top100_tickers = pd.DataFrame(top100_tickers)\n",
    "top100_tickers.to_csv('top100_tickers_2.csv', index = False)\n",
    "b2.put_file('top100_tickers_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf3c19e-2d4d-462e-8f6f-979e3efcc562",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dates = pd.date_range(start = '2023-01-01', end = '2025-12-31', freq = 'MS', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2023-01-01', end = '2025-12-31', freq = 'M', inclusive = 'both').date\n",
    "\n",
    "start_dates = start_dates[::3]\n",
    "end_dates   = end_dates[2::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5706489c-e250-4d3e-86d7-e612a4f63621",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:10\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/py311-stable/lib/python3.11/site-packages/pandas/core/reshape/concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/.conda/envs/py311-stable/lib/python3.11/site-packages/pandas/core/reshape/concat.py:429\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    426\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# A2XX or XJSE\n",
    "exchange = 'A2XX'\n",
    "for ticker in top100_tickers:\n",
    "    stock = []\n",
    "    for i in range(len(start_dates)):\n",
    "        data = get_data(exchange, ticker, start_dates[i], end_dates[i])\n",
    "        if data is not None:\n",
    "            stock.append(data)\n",
    "\n",
    "    if len(stock) == 0:\n",
    "        continue\n",
    "    \n",
    "    stock_data = pd.concat(stock, ignore_index = True)\n",
    "    stock_data.to_csv(f'{ticker}_{exchange}.csv', index = False)\n",
    "    b2.put_file(f'{ticker}_{exchange}.csv', 'top_100(Volume)')\n",
    "    print(ticker)\n",
    "\n",
    "# takes about 5 hours to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ccbce8-4b6a-4410-9a49-047b4db937d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-stable",
   "language": "python",
   "name": "py311-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
