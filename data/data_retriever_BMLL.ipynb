{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c017cae-80ef-43c9-8376-8418ce8a1c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: openpyxl in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (3.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: et-xmlfile in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ffab10-15cd-4aae-909a-666ac5c016c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import bmll2 as b2\n",
    "from bmll2 import reference, Security, NormalisedSecurity, SparkHelper, get_market_data, get_market_data_range, VenueMarketError, save_spark_dataframe, load_spark_dataframe\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07bb5c24-afe0-47fe-8bd5-fd4a2e00b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ticker, starting_date, ending_date):\n",
    "\n",
    "    #if isinstance(startingdate, str):\n",
    "    #    date = pd.to_datetime(date).date()\n",
    "    \n",
    "    try:\n",
    "        trade_plus = get_market_data_range('XJSE', start_date = starting_date, end_date = ending_date,\n",
    "                                   table_name = 'trades-plus', df_engine = 'polars', ticker = ticker,\n",
    "                                   columns = ['Classification', 'MIC', 'Ticker', 'ListingId', 'TradeDate',\n",
    "                                              'LocalTradeTimestamp', 'ExchangeSequenceNo', 'AggressorSide',\n",
    "                                              'Price', 'Size', 'PreTradeMid1ms', 'PostTradeMid1ms'])\n",
    "    except VenueMarketError:\n",
    "        return None\n",
    "        \n",
    "    trade_plus = trade_plus.to_pandas()\n",
    "    trade_plus = trade_plus[(trade_plus['Classification'] == 'LIT_CONTINUOUS')]\n",
    "    \n",
    "    if trade_plus is None or trade_plus.empty:\n",
    "        return None\n",
    "        \n",
    "    trade_plus = trade_plus[['MIC', 'Ticker', 'ListingId', 'TradeDate', 'LocalTradeTimestamp', 'ExchangeSequenceNo',\n",
    "                             'AggressorSide', 'Price', 'Size', 'PreTradeMid1ms', 'PostTradeMid1ms']]\n",
    "    trade_plus['AggressorSide'] = trade_plus['AggressorSide'].map({1 : 1, 2 : -1, 0 : 0})\n",
    "    trade_plus = trade_plus.rename(columns = {'AggressorSide' : 'Trade Sign', 'PreTradeMid1ms' : 'Mid-price before',\n",
    "                                              'PostTradeMid1ms' : 'Mid-price after(immediate)', 'Size' : 'Volume',\n",
    "                                              'LocalTradeTimestamp' : 'DateTime', 'TradeDate' : 'Date'})\n",
    "    midprice_after_delayed = trade_plus['Mid-price before'].shift(-1)\n",
    "    trade_plus.insert(loc = 11, column = 'Mid-price after(delayed)', value = midprice_after_delayed)\n",
    "    \n",
    "    l1 = get_market_data_range('XJSE', start_date = starting_date, end_date = ending_date, ticker = ticker,\n",
    "                               table_name = 'l1', df_engine = 'polars')\n",
    "    l1 = l1.to_pandas()\n",
    "    l1 = l1[l1['MarketState'] == 'CONTINUOUS_TRADING']\n",
    "    midprice = (l1['AskPrice1'] + l1['BidPrice1']) / 2\n",
    "    l1.insert(loc = 5, column = 'Mid-price', value = midprice)\n",
    "    l1 = l1.rename(columns = {'TradeDate' : 'Date'})\n",
    "    l1 = l1.sort_values(by = ['Date', 'ExchangeSequenceNo'])\n",
    "    daily_vol = (l1.groupby('Date', as_index = False)['Mid-price'].apply(lambda x: (x.max() - x.min()) / x.iloc[0])).rename(columns = {'Mid-price' : 'Daily Volatility'})\n",
    "    daily_vol_alt = (l1.groupby('Date', as_index = False)['Mid-price'].apply(lambda x: np.log(x.max()) - np.log(x.min()))).rename(columns = {'Mid-price' : 'Daily Volatility(alt)'})\n",
    "    trade_plus = pd.merge(trade_plus, daily_vol, on = 'Date', how = 'left')\n",
    "    trade_plus = pd.merge(trade_plus, daily_vol_alt, on = 'Date', how = 'left')\n",
    "\n",
    "    col = 'Daily Volatility'\n",
    "    cols = list(trade_plus.columns)\n",
    "    cols.insert(6, cols.pop(cols.index(col)))\n",
    "    \n",
    "    #col = 'Daily Volatility(alt)'\n",
    "    #cols = list(trade_plus.columns)\n",
    "    #cols.insert(7, cols.pop(cols.index(col)))\n",
    "    \n",
    "    trade_plus = trade_plus[cols]\n",
    "    daily_volume = (trade_plus.groupby('Date', as_index = False)['Volume'].sum().rename(columns = {'Volume' : 'Daily Volume'}))\n",
    "    trade_plus = pd.merge(trade_plus, daily_volume, on = 'Date', how = 'left')\n",
    "    col = 'Daily Volume'\n",
    "    cols = list(trade_plus.columns)\n",
    "    cols.insert(6, cols.pop(cols.index(col)))\n",
    "    trade_plus = trade_plus[cols]\n",
    "    #trade_plus.insert(loc = 6, column = 'Daily Volume', value = trade_plus['Volume'].sum())\n",
    "    \n",
    "    trade_plus.sort_values(['DateTime', 'ExchangeSequenceNo'])\n",
    "    return trade_plus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cada0078-b702-418d-9058-5dd140afc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2.get_file('other/JSE_listed_securities.xlsx')\n",
    "JSE_listed_securities = pd.read_excel('JSE_listed_securities.xlsx')\n",
    "\n",
    "JSE_listed_securities = JSE_listed_securities.drop(columns = ['Value', 'Change', 'Unnamed: 4', 'High', 'Low'])\n",
    "JSE_listed_securities = JSE_listed_securities.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503c6d56-276e-4e5b-a1ec-257937be397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    if(isinstance(x, (int, float))):\n",
    "        ans = x\n",
    "    elif(x[-1:] == 'M'):\n",
    "        ans = float(x[:-1]) * 1000000\n",
    "    elif(x[-1:] == 'K'):\n",
    "        ans = float(x[:-1]) * 1000\n",
    "    else:\n",
    "        ans = 0\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a824a1ed-1f45-45bd-b0c6-deecb4b7bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSE_listed_securities['Volume'] = JSE_listed_securities['Volume'].apply(clean)\n",
    "JSE_listed_securities = JSE_listed_securities.sort_values('Volume', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ca0add-b09e-4c38-9fd0-167fcdd7fce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHM\n",
      "ECS\n",
      "RMI\n",
      "AHB\n",
      "TCP\n",
      "CCO\n",
      "CTA\n",
      "AMS\n"
     ]
    }
   ],
   "source": [
    "top100_tickers = []\n",
    "i = 0\n",
    "while len(top100_tickers) < 100:\n",
    "    test = get_data(JSE_listed_securities['Symbol'].iloc[i], '2025-12-01', '2025-12-07')\n",
    "    if test is None:\n",
    "        print(JSE_listed_securities['Symbol'].iloc[i])\n",
    "    else:\n",
    "        top100_tickers.append(JSE_listed_securities['Symbol'].iloc[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95796bcf-72f4-4a3d-b613-ded5e89b9ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dates = pd.date_range(start = '2023-01-01', end = '2025-12-31', freq = 'MS', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2023-01-01', end = '2025-12-31', freq = 'M', inclusive = 'both').date\n",
    "\n",
    "start_dates = start_dates[::3]\n",
    "end_dates   = end_dates[2::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da3c9019-b7fd-4b07-921e-21ca9903219e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAB\n",
      "PPH\n",
      "FSR\n",
      "OMU\n",
      "WHL\n",
      "SSW\n",
      "FTB\n",
      "ORN\n",
      "PAN\n",
      "GLN\n",
      "PIK\n",
      "RDF\n",
      "OUT\n",
      "SOL\n",
      "GRT\n",
      "MTN\n",
      "IMP\n",
      "LHC\n",
      "SAP\n",
      "SLM\n",
      "SAC\n",
      "TRU\n",
      "OPA\n",
      "SBK\n",
      "ABG\n",
      "VKE\n",
      "NTC\n",
      "CPR\n",
      "SSU\n",
      "DRD\n",
      "KP2\n",
      "HAR\n",
      "MTM\n",
      "KAP\n",
      "DCP\n",
      "N91\n",
      "DSY\n",
      "GFI\n",
      "APN\n",
      "NPH\n",
      "DIB\n",
      "MDI\n",
      "NPN\n",
      "AEL\n",
      "SHP\n",
      "GND\n",
      "CCD\n",
      "QLT\n",
      "CML\n",
      "PPC\n",
      "VAL\n",
      "INL\n",
      "INP\n",
      "MRP\n",
      "JBL\n",
      "BLU\n",
      "NED\n",
      "S32\n",
      "TFG\n",
      "VOD\n",
      "NRP\n",
      "BYI\n",
      "NY1\n",
      "REM\n",
      "KST\n",
      "MNP\n",
      "BVT\n",
      "FFB\n",
      "ACL\n",
      "ANG\n",
      "BTI\n",
      "SRE\n",
      "CLS\n",
      "ITE\n",
      "PRX\n",
      "ARI\n",
      "RBO\n",
      "SPG\n",
      "WBC\n",
      "LTE\n",
      "SSS\n",
      "AGL\n",
      "BID\n",
      "PPE\n",
      "AFT\n",
      "TKG\n",
      "EQU\n",
      "YRK\n",
      "MSP\n",
      "TGA\n",
      "AEG\n",
      "OMN\n",
      "BTN\n",
      "AFE\n",
      "AVI\n",
      "EXX\n",
      "RNI\n",
      "BHG\n",
      "BOX\n",
      "ANH\n",
      "CPU times: user 7h 8min 41s, sys: 50min 38s, total: 7h 59min 19s\n",
      "Wall time: 5h 8min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for ticker in top100_tickers:\n",
    "    print(ticker)\n",
    "    stock = []\n",
    "    for i in range(len(start_dates)):\n",
    "        data = get_data(ticker, start_dates[i], end_dates[i])\n",
    "        if data is not None:\n",
    "            stock.append(data)\n",
    "    \n",
    "    stock_data = pd.concat(stock, ignore_index = True)\n",
    "    stock_data.to_csv(f'{ticker}.csv', index = False)\n",
    "    b2.put_file(f'{ticker}.csv', 'top_100(Volume)')\n",
    "\n",
    "# takes about 5 hours to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1d2f603-4bb1-44bd-9cbb-dad0e2963ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01 2023-01-31\n",
      "2023-02-01 2023-02-28\n",
      "2023-03-01 2023-03-31\n",
      "2023-04-01 2023-04-30\n",
      "2023-05-01 2023-05-31\n",
      "2023-06-01 2023-06-30\n",
      "2023-07-01 2023-07-31\n",
      "2023-08-01 2023-08-31\n",
      "2023-09-01 2023-09-30\n",
      "2023-10-01 2023-10-31\n",
      "2023-11-01 2023-11-30\n",
      "2023-12-01 2023-12-31\n",
      "2024-01-01 2024-01-31\n",
      "2024-02-01 2024-02-29\n",
      "2024-03-01 2024-03-31\n",
      "2024-04-01 2024-04-30\n",
      "2024-05-01 2024-05-31\n",
      "2024-06-01 2024-06-30\n",
      "2024-07-01 2024-07-31\n",
      "2024-08-01 2024-08-31\n",
      "2024-09-01 2024-09-30\n",
      "2024-10-01 2024-10-31\n",
      "2024-11-01 2024-11-30\n",
      "2024-12-01 2024-12-31\n",
      "2025-01-01 2025-01-31\n",
      "2025-02-01 2025-02-28\n",
      "2025-03-01 2025-03-31\n",
      "2025-04-01 2025-04-30\n",
      "2025-05-01 2025-05-01\n",
      "2025-05-02 2025-05-02\n",
      "2025-05-05 2025-05-05\n",
      "2025-05-06 2025-05-06\n",
      "2025-05-07 2025-05-07\n",
      "2025-05-08 2025-05-08\n",
      "2025-05-09 2025-05-09\n",
      "2025-05-12 2025-05-12\n",
      "2025-05-13 2025-05-13\n",
      "2025-05-14 2025-05-14\n",
      "2025-05-15 2025-05-15\n",
      "2025-05-16 2025-05-16\n",
      "2025-05-19 2025-05-19\n",
      "2025-05-20 2025-05-20\n",
      "2025-05-21 2025-05-21\n",
      "2025-05-22 2025-05-22\n",
      "2025-05-23 2025-05-23\n",
      "2025-05-26 2025-05-26\n",
      "2025-05-27 2025-05-27\n",
      "2025-05-27 2025-05-27\n",
      "2025-05-28 2025-05-28\n",
      "2025-05-29 2025-05-29\n",
      "2025-05-30 2025-05-30\n",
      "2025-06-01 2025-06-30\n",
      "2025-07-01 2025-07-31\n",
      "2025-08-01 2025-08-31\n",
      "2025-09-01 2025-09-30\n",
      "2025-10-01 2025-10-31\n",
      "2025-11-01 2025-11-30\n",
      "2025-12-01 2025-12-31\n"
     ]
    }
   ],
   "source": [
    "# I need to do this because the ticker for VAL was AMS before 2025-05-28\n",
    "%%time\n",
    "start_dates = pd.date_range(start = '2023-01-01', end = '2025-04-30', freq = 'MS', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2023-01-01', end = '2025-04-30', freq = 'M', inclusive = 'both').date\n",
    "\n",
    "VAL = []\n",
    "for i in range(len(start_dates)):\n",
    "    print(start_dates[i], end_dates[i])\n",
    "    data = get_data('AMS', start_dates[i], end_dates[i])\n",
    "    if data is not None:\n",
    "        VAL.append(data)\n",
    "\n",
    "start_dates = pd.date_range(start = '2025-05-01', end = '2025-05-27', freq = 'B', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2025-05-01', end = '2025-05-27', freq = 'B', inclusive = 'both').date\n",
    "\n",
    "for i in range(len(start_dates)):\n",
    "    print(start_dates[i], end_dates[i])\n",
    "    data = get_data('AMS', start_dates[i], end_dates[i])\n",
    "    if data is not None:\n",
    "        VAL.append(data)\n",
    "\n",
    "start_dates = pd.date_range(start = '2025-05-27', end = '2025-05-31', freq = 'B', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2025-05-27', end = '2025-05-31', freq = 'B', inclusive = 'both').date\n",
    "\n",
    "for i in range(len(start_dates)):\n",
    "    print(start_dates[i], end_dates[i])\n",
    "    data = get_data('VAL', start_dates[i], end_dates[i])\n",
    "    if data is not None:\n",
    "        VAL.append(data)\n",
    "\n",
    "start_dates = pd.date_range(start = '2025-06-01', end = '2025-12-31', freq = 'MS', inclusive = 'both').date\n",
    "end_dates   = pd.date_range(start = '2025-06-01', end = '2025-12-31', freq = 'M', inclusive = 'both').date\n",
    "\n",
    "for i in range(len(start_dates)):\n",
    "    print(start_dates[i], end_dates[i])\n",
    "    data = get_data('VAL', start_dates[i], end_dates[i])\n",
    "    if data is not None:\n",
    "        VAL.append(data)\n",
    "\n",
    "VAL_data = pd.concat(VAL, ignore_index = True)\n",
    "VAL_data['Ticker'] = 'VAL'\n",
    "VAL_data.to_csv('VAL.csv', index = False)\n",
    "b2.put_file('VAL.csv', 'top_100(Volume)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a1f9877-196b-4ef0-a356-710bd701d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100_tickers = pd.DataFrame(top100_tickers)\n",
    "top100_tickers.to_csv('top100_tickers.csv', index = False)\n",
    "b2.put_file('top100_tickers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998da834-0a5a-4b10-9d5d-f254503a7ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e72a02-d125-4c81-9512-220884398fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-stable",
   "language": "python",
   "name": "py311-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
