{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a08f11a-e198-49fa-a715-ccca1110e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting powerlaw\n",
      "  Downloading powerlaw-2.0.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: scipy in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from powerlaw) (1.14.1)\n",
      "Requirement already satisfied: numpy in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from powerlaw) (1.26.0)\n",
      "Requirement already satisfied: matplotlib in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from powerlaw) (3.8.1)\n",
      "Collecting mpmath (from powerlaw)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: tqdm in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from powerlaw) (4.66.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from matplotlib->powerlaw) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from matplotlib->powerlaw) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from matplotlib->powerlaw) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from matplotlib->powerlaw) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from matplotlib->powerlaw) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from matplotlib->powerlaw) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from matplotlib->powerlaw) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from matplotlib->powerlaw) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/bmll/.conda/envs/py311-stable/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->powerlaw) (1.17.0)\n",
      "Downloading powerlaw-2.0.0-py3-none-any.whl (191 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, powerlaw\n",
      "Successfully installed mpmath-1.3.0 powerlaw-2.0.0\n"
     ]
    }
   ],
   "source": [
    "import bmll2 as b2\n",
    "b2.get_file('modules/auxiliary_functions.py')\n",
    "!pip install 'powerlaw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf20c5b-626c-4fe3-bdcb-13bb053991a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do this when i have converted the notebooks to .py files\n",
    "# import auxiliary_functions\n",
    "import auxiliary_functions as af\n",
    "\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import StringDtype\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import LogFormatterSciNotation\n",
    "\n",
    "from statsmodels.sandbox.stats.runs import runstest_1samp \n",
    "import powerlaw\n",
    "import itertools\n",
    "import pylab\n",
    "import scipy.stats\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42110200-b0f5-4465-ab06-c66d391a555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top40_tickers = [\n",
    "    \"ABG\",  # ABSA\n",
    "    \"AGL\",  # Anglo American\n",
    "    \"ANG\",  # Anglogold Ashanti\n",
    "    \"ANH\",  # AB InBev\n",
    "    \"APN\",  # Aspen Pharmacare\n",
    "    \"BHG\",  # BHP Group\n",
    "    \"BID\",  # Bidcorp\n",
    "    \"BVT\",  # Bidvest\n",
    "    \"BTI\",  # British American Tobacco\n",
    "    \"CPI\",  # Capitec\n",
    "    \"CLS\",  # Clicks\n",
    "    \"DSY\",  # Discovery  \n",
    "    \"EXX\",  # Exxaro\n",
    "    \"FSR\",  # FirstRand\n",
    "    \"GLN\",  # Glencore\n",
    "    \"GFI\",  # Gold Fields\n",
    "    \"GRT\",  # Growthpoint\n",
    "    \"IMP\",  # Impala Platinum\n",
    "    \"INL\",  # Investec Ltd\n",
    "    \"INP\",  # Investec PLC\n",
    "    \"MNP\",  # Mondi\n",
    "    \"MRP\",  # Mr Price\n",
    "    \"MTN\",  # MTN Group\n",
    "    \"NPN\",  # Naspers\n",
    "    \"NED\",  # Nedbank\n",
    "    \"NRP\",  # NEPI Rockcastle\n",
    "    \"OMU\",  # Old Mutual\n",
    "    \"PRX\",  # Prosus\n",
    "    \"RNI\",  # Reinet Investments\n",
    "    \"REM\",  # Remgro\n",
    "    \"RMH\",  # RMB\n",
    "    \"SLM\",  # Sanlam\n",
    "    \"SOL\",  # Sasol\n",
    "    \"SHP\",  # Shoprite\n",
    "    \"SBK\",  # Standard Bank\n",
    "    \"VAL\",  # Valterra platinum\n",
    "    \"VOD\",  # Vodacom\n",
    "    \"WHL\"   # Woolworths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "844b4779-3ad7-4105-b2c0-6ea4bc81be5a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 17s, sys: 1min 8s, total: 5min 26s\n",
      "Wall time: 5min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files = b2.list_files(path = 'top_40')\n",
    "\n",
    "for f in files:\n",
    "    b2.get_file(f'top_40/{f}')\n",
    "    \n",
    "def load_stock(csv):\n",
    "    df = pd.read_csv(csv, parse_dates = ['DateTime', 'Date'])\n",
    "    df = df.rename(columns = {'Ticker': 'RIC'})\n",
    "    return df\n",
    "    \n",
    "stocks = {\n",
    "    ticker: load_stock(f'{ticker}.csv')\n",
    "    for ticker in top40_tickers\n",
    "}\n",
    "\n",
    "# takes about 6 minutes to load all 40 stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead1263f-321a-4d92-a1a6-3e2c834e8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sided_runs_test(sample, runs_correction = 0):\n",
    "    sample = pd.Series(sample)\n",
    "    values = sample.unique()\n",
    "\n",
    "    if (len(values) < 2):\n",
    "        return 'Only 1 unique value present'\n",
    "        \n",
    "    a = values[0]\n",
    "    b = values[1]\n",
    "\n",
    "    N_a  = len(sample[sample == a])\n",
    "    N_b  = len(sample[sample == b])\n",
    "    N    = N_a + N_b\n",
    "    mu   = ((2 * N_a * N_b) / N) + 1\n",
    "    runs = itertools.groupby(sample)\n",
    "    R    = sum(1 for _ in runs)\n",
    "    R_corrected = R + runs_correction\n",
    "\n",
    "    sigma = np.sqrt((2 * N_a * N_b * (2 * N_a * N_b - N)) / (N ** 2 * (N - 1)))\n",
    "    z     = (R_corrected - mu) / sigma\n",
    "\n",
    "    p_value = scipy.stats.norm.cdf(z)\n",
    "\n",
    "    return (z, p_value, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e75433e-2618-4f0e-89fb-5811356c60e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with ABG for 2023\n",
      "done with ABG for 2024\n",
      "done with ABG for 2025\n",
      "done with AGL for 2023\n",
      "done with AGL for 2024\n",
      "done with AGL for 2025\n",
      "done with ANG for 2023\n",
      "done with ANG for 2024\n",
      "done with ANG for 2025\n",
      "done with ANH for 2023\n",
      "done with ANH for 2024\n",
      "done with ANH for 2025\n",
      "done with APN for 2023\n",
      "done with APN for 2024\n",
      "done with APN for 2025\n",
      "done with BHG for 2023\n",
      "done with BHG for 2024\n",
      "done with BHG for 2025\n",
      "done with BID for 2023\n",
      "done with BID for 2024\n",
      "done with BID for 2025\n",
      "done with BVT for 2023\n",
      "done with BVT for 2024\n",
      "done with BVT for 2025\n",
      "done with BTI for 2023\n",
      "done with BTI for 2024\n",
      "done with BTI for 2025\n",
      "done with CPI for 2023\n",
      "done with CPI for 2024\n",
      "done with CPI for 2025\n",
      "done with CLS for 2023\n",
      "done with CLS for 2024\n",
      "done with CLS for 2025\n",
      "done with DSY for 2023\n",
      "done with DSY for 2024\n",
      "done with DSY for 2025\n",
      "done with EXX for 2023\n",
      "done with EXX for 2024\n",
      "done with EXX for 2025\n",
      "done with FSR for 2023\n",
      "done with FSR for 2024\n",
      "done with FSR for 2025\n",
      "done with GLN for 2023\n",
      "done with GLN for 2024\n",
      "done with GLN for 2025\n",
      "done with GFI for 2023\n",
      "done with GFI for 2024\n",
      "done with GFI for 2025\n",
      "done with GRT for 2023\n",
      "done with GRT for 2024\n",
      "done with GRT for 2025\n",
      "done with IMP for 2023\n",
      "done with IMP for 2024\n",
      "done with IMP for 2025\n",
      "done with INL for 2023\n",
      "done with INL for 2024\n",
      "done with INL for 2025\n",
      "done with INP for 2023\n",
      "done with INP for 2024\n",
      "done with INP for 2025\n",
      "done with MNP for 2023\n",
      "done with MNP for 2024\n",
      "done with MNP for 2025\n",
      "done with MRP for 2023\n",
      "done with MRP for 2024\n",
      "done with MRP for 2025\n",
      "done with MTN for 2023\n",
      "done with MTN for 2024\n",
      "done with MTN for 2025\n",
      "done with NPN for 2023\n",
      "done with NPN for 2024\n",
      "done with NPN for 2025\n",
      "done with NED for 2023\n",
      "done with NED for 2024\n",
      "done with NED for 2025\n",
      "done with NRP for 2023\n",
      "done with NRP for 2024\n",
      "done with NRP for 2025\n",
      "done with OMU for 2023\n",
      "done with OMU for 2024\n",
      "done with OMU for 2025\n",
      "done with PRX for 2023\n",
      "done with PRX for 2024\n",
      "done with PRX for 2025\n",
      "done with RNI for 2023\n",
      "done with RNI for 2024\n",
      "done with RNI for 2025\n",
      "done with REM for 2023\n",
      "done with REM for 2024\n",
      "done with REM for 2025\n",
      "done with RMH for 2023\n",
      "done with RMH for 2024\n",
      "done with RMH for 2025\n",
      "done with SLM for 2023\n",
      "done with SLM for 2024\n",
      "done with SLM for 2025\n",
      "done with SOL for 2023\n",
      "done with SOL for 2024\n",
      "done with SOL for 2025\n",
      "done with SHP for 2023\n",
      "done with SHP for 2024\n",
      "done with SHP for 2025\n",
      "done with SBK for 2023\n",
      "done with SBK for 2024\n",
      "done with SBK for 2025\n",
      "done with VAL for 2023\n",
      "done with VAL for 2024\n",
      "done with VAL for 2025\n",
      "done with VOD for 2023\n",
      "done with VOD for 2024\n",
      "done with VOD for 2025\n",
      "done with WHL for 2023\n",
      "done with WHL for 2024\n",
      "done with WHL for 2025\n",
      "CPU times: user 1h 52min 49s, sys: 12.6 s, total: 1h 53min 2s\n",
      "Wall time: 1h 53min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stocks_trade_sequences    = [] # will be a 3 deep list. 40 stocks, all days, < 10 sequences per day, indexes of trades for ST traders\n",
    "stocks_p_vals             = [] # will be a 3 deep list. 40 stocks, all days, < 10 p vals per day, a single value per ST trader\n",
    "stocks_run_lengths        = [] # will be a 3 deep list. 40 stocks, all days, < 10 traders per day, run lengths of each metaorder\n",
    "stocks_total_volumes      = [] # will be a 2 deep list, 40 stocks, all days, total volume traded per day of each stock\n",
    "stocks_percentage_STs     = [] \n",
    "stocks_percentage_STs_vol = []\n",
    "stocks_percentage_STs_num = []\n",
    "\n",
    "for ric, stock_data in stocks.items():\n",
    "\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "    stock_data['Year'] = stock_data['Date'].dt.year\n",
    "\n",
    "    for year, df_year in stock_data.groupby('Year'):\n",
    "    \n",
    "        trader_trade_sequences      = [] # will be a 2 deep list. all days, < 10 sequences per day, indexes of trades for ST traders\n",
    "        trader_p_vals               = [] # will be a 2 deep list. all days, < 10 p vals per day, a single value per ST trader\n",
    "        trader_run_lengths          = [] # will be a 2 deep list. all days, < 10 traders per day, run lengths of each metaorder\n",
    "        trader_total_volumes        = [] # will be a 1 deep list. all days, total volume traded per day\n",
    "        trader_percentage_STs       = []\n",
    "        trader_percentage_STs_vol   = []\n",
    "        trader_percentage_STs_num   = []\n",
    "        \n",
    "        N = 25\n",
    "    \n",
    "        f = af.trader_participation(N = N, method = 'power', alpha = 2, f_min = 1, f_max = stock_data.shape[0], seed = 1)\n",
    "        c = af.cumulative_probs(f)\n",
    "    \n",
    "        if stock_data.empty:\n",
    "            continue\n",
    "    \n",
    "        output = af.orders(N = N, trades = df_year, cumulative_probs = c)\n",
    "        \n",
    "        STs_volume = 0\n",
    "        STs_num    = 0\n",
    "        for n in range(N):\n",
    "    \n",
    "            trader_n_trades = df_year.iloc[output[n], ]\n",
    "    \n",
    "            if (trader_n_trades.shape[0] <= 2):\n",
    "                continue\n",
    "    \n",
    "            if (trader_n_trades['Trade Sign'].nunique() < 2):\n",
    "                continue\n",
    "    \n",
    "            day_breaks = 0\n",
    "            prev_date  = None\n",
    "            prev_sign  = None\n",
    "            \n",
    "            for idx, row in trader_n_trades.iterrows():\n",
    "                current_date = row['Date']\n",
    "                current_sign = row['Trade Sign']\n",
    "                \n",
    "                # If we've moved to a new day and the sign is THE SAME from end of previous day\n",
    "                if prev_date is not None and current_date != prev_date and current_sign == prev_sign:\n",
    "                    day_breaks += 1\n",
    "                \n",
    "                prev_date = current_date\n",
    "                prev_sign = current_sign\n",
    "    \n",
    "            runs_test = one_sided_runs_test(trader_n_trades['Trade Sign'], runs_correction = day_breaks)\n",
    "            p_val     = runs_test[1]\n",
    "    \n",
    "            # we need to decide on an appropriate p value here. 1% seems too strict\n",
    "            if p_val <= 0.01:\n",
    "    \n",
    "                STs_volume = STs_volume + sum(trader_n_trades['Volume'])\n",
    "                STs_num    = STs_num + trader_n_trades.shape[0]\n",
    "                trader_trade_sequences.append(trader_n_trades)\n",
    "                trader_p_vals.append(p_val)\n",
    "                \n",
    "                grouped_trade_signs = itertools.groupby(trader_n_trades['Trade Sign'])\n",
    "                \n",
    "                for key, group in grouped_trade_signs:\n",
    "                    trader_run_lengths.append(len(list(group)))\n",
    "    \n",
    "            #STs_percentage_vol = round((STs_volume / sum(stock_data['Volume'])) * 100, 3)\n",
    "            #STs_percentage_num = round((STs_num / stock_data.shape[0]) * 100, 3)\n",
    "                                                  \n",
    "            #trader_trade_sequences.append(days_trade_sequences)\n",
    "            #trader_p_vals.append(days_p_vals)\n",
    "            #trader_sequence_run_lengths.append(days_run_lengths)\n",
    "            trader_total_volumes.append(sum(stock_data['Volume']))\n",
    "            #trader_percentage_STs.append(round((len(trader_trade_sequences) / N) * 100, 3))\n",
    "            #trader_percentage_STs_vol.append(STs_percentage_vol)\n",
    "            #trader_percentage_STs_num.append(STs_percentage_num)\n",
    "\n",
    "        STs_percentage_vol = round((STs_volume / sum(stock_data['Volume'])) * 100, 3)\n",
    "        STs_percentage_num = round((STs_num / stock_data.shape[0]) * 100, 3)\n",
    "        \n",
    "        stocks_trade_sequences.append(trader_trade_sequences)\n",
    "        stocks_p_vals.append(trader_p_vals)\n",
    "        stocks_run_lengths.append(trader_run_lengths)\n",
    "        stocks_total_volumes.append(trader_total_volumes)\n",
    "        stocks_percentage_STs.append(round((len(trader_trade_sequences) / N) * 100, 3))\n",
    "        stocks_percentage_STs_vol.append(STs_percentage_vol)\n",
    "        stocks_percentage_STs_num.append(STs_percentage_num)\n",
    "        print('done with', ric, 'for', year)\n",
    "\n",
    "# takes about 2 hours to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55d29175-1905-45a5-b32a-f2a76ce16cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_percentage_STs     = np.array(stocks_percentage_STs)\n",
    "stocks_percentage_STs_vol = np.array(stocks_percentage_STs_vol)\n",
    "stocks_percentage_STs_num = np.array(stocks_percentage_STs_num)\n",
    "\n",
    "STs_percentage = stocks_percentage_STs[stocks_percentage_STs > 0]\n",
    "STs_vols       = stocks_percentage_STs_vol[stocks_percentage_STs_vol > 0]\n",
    "STs_nums       = stocks_percentage_STs_num[stocks_percentage_STs_num > 0]\n",
    "\n",
    "ST_df          = pd.DataFrame({'% STs' : STs_percentage, 'STs volume' : STs_vols, 'STs number' : STs_nums})\n",
    "ST_df.to_csv('ST_df_power_25.csv', index = False)\n",
    "b2.put_file('ST_df_power_25.csv', 'test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2696d0eb-5bd1-40e1-9120-4f0d104c1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ST_run_lengths(stock_data, N = 100, p_threshold = 0.01):\n",
    "    \"\"\"\n",
    "    Extracts metaorder run lengths L from statistically identified\n",
    "    splitting traders (STs) for a given stock and time window.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    run_lengths : list of int\n",
    "        Metaorder lengths pooled across ST traders\n",
    "    \"\"\"\n",
    "    run_lengths = []\n",
    "\n",
    "    # Synthetic trader reconstruction (your existing method)\n",
    "    f = af.trader_participation(N = N, method = 'power', alpha =  2, f_min = 1 ,f_max = stock_data.shape[0], seed = 1)\n",
    "    c = af.cumulative_probs(f)\n",
    "    output = af.orders(N = N, trades = stock_data, cumulative_probs = c)\n",
    "\n",
    "    for n in range(N):\n",
    "        trader_trades = stock_data.iloc[output[n]]\n",
    "\n",
    "        # Too few trades → useless\n",
    "        if trader_trades.shape[0] <= 2:\n",
    "            continue\n",
    "\n",
    "        # No sign variation → no runs test\n",
    "        if trader_trades['Trade Sign'].nunique() < 2:\n",
    "            continue\n",
    "\n",
    "        # Correct runs across day boundaries\n",
    "        day_breaks = 0\n",
    "        prev_date  = None\n",
    "        prev_sign  = None\n",
    "\n",
    "        for idx, row in trader_trades.iterrows():\n",
    "            if prev_date is not None:\n",
    "                if row['Date'] != prev_date and row['Trade Sign'] == prev_sign:\n",
    "                    day_breaks += 1\n",
    "            prev_date = row['Date']\n",
    "            prev_sign = row['Trade Sign']\n",
    "\n",
    "        z, p_val, R = one_sided_runs_test(trader_trades['Trade Sign'], runs_correction = day_breaks)\n",
    "\n",
    "        # Identify splitting traders\n",
    "        if p_val <= p_threshold:\n",
    "            for key, group in itertools.groupby(trader_trades['Trade Sign']):\n",
    "                run_lengths.append(len(list(group)))\n",
    "\n",
    "    return run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec59f11-79fd-40f8-b8a0-c3b41845130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for ticker, stock_data in stocks.items():\n",
    "\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "    stock_data['Year'] = stock_data['Date'].dt.year\n",
    "\n",
    "    for year, df_year in stock_data.groupby('Year'):\n",
    "\n",
    "        if df_year.shape[0] < 1000:\n",
    "            continue  # too small for power laws\n",
    "\n",
    "        L = extract_ST_run_lengths(df_year)\n",
    "        signs = df_year['Trade Sign']\n",
    "        \n",
    "        if len(L) == 0:\n",
    "            continue\n",
    "        \n",
    "        out = pd.DataFrame({'L' : L})\n",
    "        out.to_csv(f'{ticker}_run_lengths_yearly_{year}.csv', index = False)\n",
    "        b2.put_file(f'{ticker}_run_lengths_yearly_{year}.csv', 'test_data')\n",
    "\n",
    "        signs = pd.DataFrame({'Trade Sign' : signs})\n",
    "        signs.to_csv(f'{ticker}_trade_signs_{year}.csv', index = False)\n",
    "        b2.put_file(f'{ticker}_trade_signs_{year}.csv', 'test_data')\n",
    "        \n",
    "    print(f'saved yearly run lengths for {ticker}')\n",
    "\n",
    "# takes about 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a3eab-5f9b-4821-a1f9-74c3c970badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def assign_half_year(date):\n",
    "    return 'H1' if date.month <= 6 else 'H2'\n",
    "\n",
    "for ticker, stock_data in stocks.items():\n",
    "\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "    stock_data['Year'] = stock_data['Date'].dt.year\n",
    "    stock_data['Half'] = stock_data['Date'].apply(assign_half_year)\n",
    "\n",
    "    for (year, half), df_half in stock_data.groupby(['Year', 'Half']):\n",
    "\n",
    "        if df_half.shape[0] < 1000:\n",
    "            continue\n",
    "\n",
    "        L = extract_ST_run_lengths(df_half)\n",
    "        signs = df_half['Trade Sign']\n",
    "        \n",
    "        if len(L) == 0:\n",
    "            continue\n",
    "\n",
    "        out = pd.DataFrame({'L': L})\n",
    "        out.to_csv(f'{ticker}_run_lengths_half_yearly_{year}_{half}.csv', index = False)\n",
    "        b2.put_file(f'{ticker}_run_lengths_half_yearly_{year}_{half}.csv', 'test_data')\n",
    "\n",
    "        signs = pd.DataFrame({'Trade Sign' : signs})\n",
    "        signs.to_csv(f'{ticker}_trade_signs_{year}_{half}.csv', index = False)\n",
    "        b2.put_file(f'{ticker}_trade_signs_{year}_{half}.csv', 'test_data')\n",
    "        \n",
    "    print(f'saved half-year run lengths for {ticker}')\n",
    "\n",
    "# takes about 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027db396-9157-4987-847b-7b633fbf0ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80737faf-eb28-4bea-be3a-c4130bb5e462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a1d45-81b5-45da-90e5-2d20de97ae71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3aa80-36bd-48a0-bae9-47ecb52e9c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbcbb23-edf6-409b-9ac2-32f3575408a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe673803-db9b-4a4e-a5c6-45b9ae846829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526d9678-18ef-416e-ab22-e1e56b8eb520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L = pd.read_csv('AGL_run_lengths_yearly_2025.csv')\n",
    "#L = np.array(L)\n",
    "\n",
    "run_lengths = pd.read_csv('AGL_run_lengths_yearly_2025.csv')\n",
    "L = run_lengths['L'].to_numpy()\n",
    "\n",
    "fit = powerlaw.Fit(L)#, xmin = 1)\n",
    "\n",
    "alpha = fit.power_law.alpha\n",
    "xmin  = fit.power_law.xmin\n",
    "\n",
    "fig = fit.plot_ccdf(color = 'blue', linewidth = 2)\n",
    "fit.power_law.plot_ccdf(color = 'red', linestyle = '--', ax = fig, label = rf'$P_{{>}}(L) = -{alpha - 1:.3f}$')\n",
    "plt.xlabel(r'$L$')\n",
    "plt.ylabel(r'$P_{>}(L)$')\n",
    "plt.legend()\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136fead9-605c-405b-adca-9af429678c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some diagnostics from here on out to test for inaccuracies or bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148a33c-46cf-41ac-a91d-f2dfedd4a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGL = data_retriever('CPI', jan_path, dec_path)\n",
    "AGL[np.isinf(AGL['Trade Sign'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b6007-c7e9-46e4-9440-8650faad76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "for date, day_D in AGL.groupby('Date', sort = False):\n",
    "    print(date)\n",
    "    f = af.trader_participation(N = N, method = 'homogenous', alpha = 2, f_min = 1, f_max = 1000, seed = 1)\n",
    "    c = af.cumulative_probs(f)\n",
    "    trades = day_D\n",
    "    if trades.empty:\n",
    "        continue\n",
    "\n",
    "    output = af.orders(N = N, trades = trades, cumulative_probs = c)\n",
    "    \n",
    "    days_trade_sequences = []\n",
    "    days_p_vals = []\n",
    "    daily_run_lengths = []\n",
    "\n",
    "    for n in range(N):\n",
    "        print(f\"Trader {n}\")\n",
    "        trader_n_trades = trades.iloc[output[n], ]\n",
    "\n",
    "        if (trader_n_trades.shape[0] <= 2):\n",
    "            continue\n",
    "\n",
    "        if (trader_n_trades['Trade Sign'].nunique() < 2):\n",
    "            #print(f\"  Skipping trader {n} - only {trader_n_trades['Trade Sign'].nunique()} unique value(s)\")\n",
    "            continue\n",
    "        \n",
    "        with warnings.catch_warnings(record = True) as w:\n",
    "            warnings.simplefilter('always')\n",
    "            runs_test = one_sided_runs_test(trader_n_trades['Trade Sign'])\n",
    "            p_val = runs_test[1]\n",
    "            \n",
    "            if len(w) > 0:\n",
    "                print(f\"  *** WARNING on trader {n}: {w[0].message}\")\n",
    "                print(f\"  len={len(trader_n_trades)}, unique={trader_n_trades['Trade Sign'].nunique()}\")\n",
    "                print(f\"  Values: {trader_n_trades['Trade Sign'].values}\")\n",
    "        \n",
    "        print(f\"  p_val={p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71382ccd-9942-4b72-96f1-7f603e8b1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sided_runs_test([-1 , 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f25f1-920b-46dc-a0c2-59818619c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each day at a time\n",
    "\n",
    "stocks_trade_sequences    = [] # will be a 3 deep list. 40 stocks, all days, < 10 sequences per day, indexes of trades for ST traders\n",
    "stocks_p_vals             = [] # will be a 3 deep list. 40 stocks, all days, < 10 p vals per day, a single value per ST trader\n",
    "stocks_run_lengths        = [] # will be a 3 deep list. 40 stocks, all days, < 10 traders per day, run lengths of each metaorder\n",
    "stocks_total_volumes      = [] # will be a 2 deep list, 40 stocks, all days, total volume traded per day of each stock\n",
    "stocks_percentage_STs     = [] \n",
    "stocks_percentage_STs_vol = []\n",
    "stocks_percentage_STs_num = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    \n",
    "    stock_data = data_retriever(ticker, jan_path, dec_path)\n",
    "\n",
    "    daily_trade_sequences      = [] # will be a 2 deep list. all days, < 10 sequences per day, indexes of trades for ST traders\n",
    "    daily_p_vals               = [] # will be a 2 deep list. all days, < 10 p vals per day, a single value per ST trader\n",
    "    daily_sequence_run_lengths = [] # will be a 2 deep list. all days, < 10 traders per day, run lengths of each metaorder\n",
    "    daily_total_volumes        = [] # will be a 1 deep list. all days, total volume traded per day\n",
    "    daily_percentage_STs       = []\n",
    "    daily_percentage_STs_vol   = []\n",
    "    daily_percentage_STs_num   = []\n",
    "    \n",
    "    N = 20\n",
    "    for date, day_D in stock_data.groupby('Date', sort = False):\n",
    "    \n",
    "            f = af.trader_participation(N = N, method = 'homogenous', alpha = 2, f_min = 1, f_max = stock_data.shape[0], seed = None)\n",
    "            c = af.cumulative_probs(f)\n",
    "    \n",
    "            trades = day_D\n",
    "            if trades.empty:\n",
    "                continue\n",
    "    \n",
    "            output = af.orders(N = N, trades = trades, cumulative_probs = c)\n",
    "            \n",
    "            days_trade_sequences = []\n",
    "            days_p_vals = []\n",
    "            days_run_lengths = []\n",
    "            #days_percentage_STs_vol = []\n",
    "            #days_percentage_STs_num = []\n",
    "\n",
    "            STs_volume = 0\n",
    "            STs_num    = 0\n",
    "            for n in range(N):\n",
    "                \n",
    "                trader_n_trades = trades.iloc[output[n], ]\n",
    "    \n",
    "                if (trader_n_trades.shape[0] <= 2):\n",
    "                    continue\n",
    "    \n",
    "                if (trader_n_trades['Trade Sign'].nunique() < 2):\n",
    "                    continue\n",
    "\n",
    "                #runs_test = runstest_1samp(trader_n_trades['Trade Sign'], correction = False)\n",
    "                runs_test = one_sided_runs_test(trader_n_trades['Trade Sign'])\n",
    "                p_val     = runs_test[1]\n",
    "    \n",
    "                # we need to decide on an appropriate p value here. 1% seems too strict\n",
    "                if p_val <= 0.05:\n",
    "\n",
    "                    STs_volume = STs_volume + sum(trader_n_trades['Volume'])\n",
    "                    STs_num    = STs_num + trader_n_trades.shape[0]\n",
    "                    days_trade_sequences.append(trader_n_trades)\n",
    "                    days_p_vals.append(p_val)\n",
    "                    \n",
    "                    grouped_trade_signs = itertools.groupby(trader_n_trades['Trade Sign'])\n",
    "                    \n",
    "                    for key, group in grouped_trade_signs:\n",
    "                        days_run_lengths.append(len(list(group)))\n",
    "\n",
    "            STs_percentage_vol = round((STs_volume / sum(trades['Volume'])) * 100, 3)\n",
    "            STs_percentage_num = round((STs_num / trades.shape[0]) * 100, 3)\n",
    "                                                  \n",
    "            daily_trade_sequences.append(days_trade_sequences)\n",
    "            daily_p_vals.append(days_p_vals)\n",
    "            daily_sequence_run_lengths.append(days_run_lengths)\n",
    "            daily_total_volumes.append(sum(trades['Volume']))\n",
    "            daily_percentage_STs.append(round((len(days_trade_sequences) / N) * 100, 3))\n",
    "            daily_percentage_STs_vol.append(STs_percentage_vol)\n",
    "            daily_percentage_STs_num.append(STs_percentage_num)\n",
    "    \n",
    "    stocks_trade_sequences.append(daily_trade_sequences)\n",
    "    stocks_p_vals.append(daily_p_vals)\n",
    "    stocks_run_lengths.append(daily_sequence_run_lengths)\n",
    "    stocks_total_volumes.append(daily_total_volumes)\n",
    "    stocks_percentage_STs.append(daily_percentage_STs)\n",
    "    stocks_percentage_STs_vol.append(daily_percentage_STs_vol)\n",
    "    stocks_percentage_STs_num.append(daily_percentage_STs_num)\n",
    "    print('done with', ticker)\n",
    "\n",
    "STs_percentage = [item for sublist in stocks_percentage_STs for item in sublist]\n",
    "STs_percentage = np.array(STs_percentage)\n",
    "\n",
    "STs_vols = [item for sublist in stocks_percentage_STs_vol for item in sublist]\n",
    "# this list comprehension works by item for (sublist in run_lengths) for item in sublist\n",
    "STs_vols = np.array(STs_vols)\n",
    "\n",
    "STs_nums = [item for sublist in stocks_percentage_STs_num for item in sublist]\n",
    "# this list comprehension works by item for (sublist in run_lengths) for item in sublist\n",
    "STs_nums = np.array(STs_nums)\n",
    "\n",
    "STs_percentage = STs_percentage[STs_percentage > 0]\n",
    "STs_vols       = STs_vols[STs_vols > 0]\n",
    "STs_nums       = STs_nums[STs_nums > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbc936-1f4e-4050-97cc-d652c1a3e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the three histograms\n",
    "fig, axes = plt.subplots(1, 3, figsize = (18, 5))\n",
    "\n",
    "# Histogram 1: Percentage of traders identified as ST\n",
    "axes[0].hist(STs_percentage, bins = 10, edgecolor = 'black', alpha = 0.7, color = 'blue')\n",
    "axes[0].set_xlabel('% of Traders Classified as ST', fontsize = 11)\n",
    "axes[0].set_ylabel('Frequency', fontsize = 11)\n",
    "axes[0].set_title('ST Traders (by count)', fontsize = 12)\n",
    "axes[0].grid(True, alpha = 0.3)\n",
    "\n",
    "# Histogram 2: Volume percentage\n",
    "axes[1].hist(STs_vols, bins = 30, edgecolor = 'black', alpha = 0.7, color = 'green')\n",
    "axes[1].set_xlabel('% of Volume from ST Traders', fontsize = 11)\n",
    "axes[1].set_ylabel('Frequency', fontsize = 11)\n",
    "axes[1].set_title('ST Volume Share', fontsize = 12)\n",
    "axes[1].grid(True, alpha = 0.3)\n",
    "\n",
    "# Histogram 3: Number of trades percentage\n",
    "axes[2].hist(STs_nums, bins = 30, edgecolor = 'black', alpha = 0.7, color = 'red')\n",
    "axes[2].set_xlabel('% of Trades from ST Traders', fontsize = 11)\n",
    "axes[2].set_ylabel('Frequency', fontsize = 11)\n",
    "axes[2].set_title('ST Trade Count Share', fontsize = 12)\n",
    "axes[2].grid(True, alpha = 0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"Total stock-days analyzed: {len(STs_percentage)}\")\n",
    "print(f\"\\nST Traders: Mean = {np.mean(STs_percentage):.2f}%, Median = {np.median(STs_percentage):.2f}%\")\n",
    "print(f\"ST Volume: Mean = {np.mean(STs_vols):.2f}%, Median = {np.median(STs_vols):.2f}%\")\n",
    "print(f\"ST Trades: Mean = {np.mean(STs_nums):.2f}%, Median = {np.median(STs_nums):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1abb6e-f26b-4a77-a9f3-4f5275a3cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [item for sublist in daily_sequence_run_lengths for item in sublist]\n",
    "# this list comprehension works by item for (sublist in run_lengths) for item in sublist\n",
    "L = np.array(L)\n",
    "\n",
    "fit = powerlaw.Fit(L, xmin = 1)\n",
    "\n",
    "alpha = fit.power_law.alpha\n",
    "xmin  = fit.power_law.xmin\n",
    "\n",
    "fig = fit.plot_ccdf(color = 'blue', linewidth = 2)\n",
    "fit.power_law.plot_ccdf(color = 'red', linestyle = '--', ax = fig, label = rf'$P_{{>}}(L) = -{alpha-1:.3f}$')\n",
    "plt.xlabel(r'$L$')\n",
    "plt.ylabel(r'$P_{>}(L)$')\n",
    "plt.legend()\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "\n",
    "pylab.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-stable",
   "language": "python",
   "name": "py311-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
